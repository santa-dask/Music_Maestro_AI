{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0a95652-561c-4ac3-a6ca-bbb88048a9e5",
      "metadata": {
        "id": "e0a95652-561c-4ac3-a6ca-bbb88048a9e5"
      },
      "source": [
        "# Deep learning techniques to identify the composer of a music piece\n",
        "\n",
        "**Objective**  \n",
        "The primary objective of this project is to develop a deep learning model that can predict the composer of a given musical score accurately. The project aims to accomplish this objective by using two deep learning techniques: Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN).\n",
        "\n",
        "**Dataset**  \n",
        "The project will use a dataset consisting of musical scores from various composers. The dataset contain MIDI files and sheet music of compositions from well-known classical composers like Bach, Beethoven, Chopin, Mozart, Schubert, etc. The dataset should be labeled with the name of the composer for each score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f8b97b7-e792-46a7-bca4-7cf4beb01dd7",
      "metadata": {
        "id": "2f8b97b7-e792-46a7-bca4-7cf4beb01dd7"
      },
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f02e2e-3a2b-41c1-870f-e09789c7c2f3",
      "metadata": {
        "id": "23f02e2e-3a2b-41c1-870f-e09789c7c2f3"
      },
      "source": [
        "## Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ee7f88e2-941a-4023-882d-72d9441f81ea",
      "metadata": {
        "id": "ee7f88e2-941a-4023-882d-72d9441f81ea"
      },
      "outputs": [],
      "source": [
        "# Import all dependent libraries\n",
        "import os\n",
        "import csv\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import warnings\n",
        "import math\n",
        "import keras.optimizers\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Music related libraries\n",
        "import music21\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# Deep Learning Libraries\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.utils import pad_sequences # not used , should we remove it?\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe105c7e-628a-4737-94f1-6b0edabfece6",
      "metadata": {
        "id": "fe105c7e-628a-4737-94f1-6b0edabfece6",
        "outputId": "935ec27a-9e52-4e32-ee1a-ff06045ee728",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive to load the input dataset.\n",
        "drive.mount('/content/drive' , force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Root path\n",
        "root_path = '/content/drive/MyDrive/AAI-511-IN2 Neural Networks and Deep Learning/Project'\n",
        "\n",
        "# File path in Google Drive\n",
        "file_path = os.path.join(root_path, 'Composer_Dataset.zip')\n",
        "\n",
        "# Extract file path\n",
        "extract_path = os.path.join(root_path, 'Composer_Dataset')\n",
        "\n",
        "# Dataset folders\n",
        "dataset_path = os.path.join(extract_path, 'Composer_Dataset/NN_midi_files_extended')\n",
        "\n",
        "# CSV index file\n",
        "csv_file = os.path.join(dataset_path, 'composer_dataset_index.csv')"
      ],
      "metadata": {
        "id": "3EEMAXwr3bKX"
      },
      "id": "3EEMAXwr3bKX",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if folder already exists\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")"
      ],
      "metadata": {
        "id": "j7VJ9Ifr46kf",
        "outputId": "cf208ab0-a2de-4eba-e8ad-29bcaa90db62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "j7VJ9Ifr46kf",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_hidden_folders(root_folder):\n",
        "    for root, dirs, _ in os.walk(root_folder):\n",
        "        for d in dirs:\n",
        "            if d.startswith('.'):\n",
        "                dir_path = os.path.join(root, d)\n",
        "                print(f\"Deleting hidden folder: {dir_path}\")\n",
        "                shutil.rmtree(dir_path)\n",
        "            elif d == '__MACOSX':\n",
        "                dir_path = os.path.join(root, d)\n",
        "                print(f\"Deleting __MACOSX folder: {dir_path}\")\n",
        "                shutil.rmtree(dir_path)\n",
        "\n",
        "# Run this on the outer Composer_Dataset\n",
        "delete_hidden_folders(extract_path)"
      ],
      "metadata": {
        "id": "4wlNACsj_Sti",
        "outputId": "6f663260-8f53-461f-c14e-e8968818af38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4wlNACsj_Sti",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting __MACOSX folder: /content/drive/MyDrive/AAI-511-IN2 Neural Networks and Deep Learning/Project/Composer_Dataset/__MACOSX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create index files\n",
        "def create_midi_file_index_csv(root_dir, output_csv):\n",
        "    rows = []\n",
        "\n",
        "    for split in ['train', 'test', 'dev']:\n",
        "        split_path = os.path.join(root_dir, split)\n",
        "        if not os.path.isdir(split_path):\n",
        "            continue\n",
        "\n",
        "        for composer in os.listdir(split_path):\n",
        "            composer_path = os.path.join(split_path, composer)\n",
        "            if not os.path.isdir(composer_path) or composer.startswith('.'):\n",
        "                continue\n",
        "\n",
        "            for filename in os.listdir(composer_path):\n",
        "                if not filename.endswith('.mid') or filename.startswith('.'):\n",
        "                    continue\n",
        "\n",
        "                filepath = os.path.join(split, composer, filename)\n",
        "                rows.append({\n",
        "                    'split': split,\n",
        "                    'composer': composer,\n",
        "                    'filename': filename,\n",
        "                    'filepath': filepath\n",
        "                })\n",
        "\n",
        "    # Write to CSV\n",
        "    with open(output_csv, 'w', newline='') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=['split', 'composer', 'filename', 'filepath'])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(rows)\n",
        "\n",
        "    print(f\"CSV created: {output_csv} with {len(rows)} entries.\")\n",
        "\n",
        "# Create a csv file\n",
        "create_midi_file_index_csv(\n",
        "    root_dir=dataset_path,\n",
        "    output_csv=csv_file\n",
        ")"
      ],
      "metadata": {
        "id": "I9exSDxI8end",
        "outputId": "32bcf927-f087-40e2-85e5-691d2501ddbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I9exSDxI8end",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV created: /content/drive/MyDrive/AAI-511-IN2 Neural Networks and Deep Learning/Project/Composer_Dataset/Composer_Dataset/NN_midi_files_extended/composer_dataset_index.csv with 439 entries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82067802-38c9-4321-840b-258d7ed2e0ba",
      "metadata": {
        "id": "82067802-38c9-4321-840b-258d7ed2e0ba"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4633d989-b9ed-444d-96e7-e249825f30b5",
      "metadata": {
        "id": "4633d989-b9ed-444d-96e7-e249825f30b5"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f2f6f57-710d-43d7-826e-13cbc147930a",
      "metadata": {
        "id": "3f2f6f57-710d-43d7-826e-13cbc147930a"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02852b8-8fdb-44f9-a30e-fa4d7d89c442",
      "metadata": {
        "id": "d02852b8-8fdb-44f9-a30e-fa4d7d89c442"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d31aed45-6d6c-4992-9dae-a2c403f084f3",
      "metadata": {
        "id": "d31aed45-6d6c-4992-9dae-a2c403f084f3"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62903365-5543-4be5-b993-08b1fa0238e8",
      "metadata": {
        "id": "62903365-5543-4be5-b993-08b1fa0238e8"
      },
      "source": [
        "## Model Optimization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}